#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Script d·ªãch file README.md sang ng√¥n ng·ªØ kh√°c
Usage: python translate_readme.py [--source README.md] [--target en] [--output README_EN.md]
"""
import argparse
import re
import sys
from pathlib import Path

try:
    from deep_translator import GoogleTranslator
    HAS_DEEP_TRANSLATOR = True
except ImportError:
    try:
        from googletrans import Translator
        HAS_GOOGLETRANS = True
        HAS_DEEP_TRANSLATOR = False
    except ImportError:
        HAS_GOOGLETRANS = False
        HAS_DEEP_TRANSLATOR = False

# Mapping ng√¥n ng·ªØ
LANG_MAP = {
    'vi': 'vi',
    'en': 'en',
    'vi-VN': 'vi',
    'en-US': 'en',
    'vietnamese': 'vi',
    'english': 'en'
}

def detect_language(text):
    """Ph√°t hi·ªán ng√¥n ng·ªØ c·ªßa text (ƒë∆°n gi·∫£n)"""
    # Ki·ªÉm tra m·ªôt s·ªë t·ª´ ti·∫øng Vi·ªát ph·ªï bi·∫øn
    vietnamese_words = ['c·ªßa', 'v√†', 'v·ªõi', 'cho', 'ƒë∆∞·ª£c', 'l√†', 'c√≥', 'trong', 'n√†y', 'ƒë·ªÉ']
    words = text.lower().split()
    vi_count = sum(1 for word in words if word in vietnamese_words)
    
    if vi_count > len(words) * 0.1:  # N·∫øu > 10% t·ª´ l√† ti·∫øng Vi·ªát
        return 'vi'
    return 'en'

def translate_text(text, source_lang, target_lang, translator=None):
    """D·ªãch text s·ª≠ d·ª•ng translator"""
    if not text.strip():
        return text
    
    try:
        if HAS_DEEP_TRANSLATOR:
            if translator is None:
                translator = GoogleTranslator(source=source_lang, target=target_lang)
            return translator.translate(text)
        elif HAS_GOOGLETRANS:
            if translator is None:
                translator = Translator()
            result = translator.translate(text, src=source_lang, dest=target_lang)
            return result.text
        else:
            print("‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ vi·ªán d·ªãch. C√†i ƒë·∫∑t: pip install deep-translator ho·∫∑c googletrans")
            return text
    except Exception as e:
        print(f"‚ö†Ô∏è  L·ªói khi d·ªãch: {e}")
        return text

def parse_markdown(content):
    """Ph√¢n t√≠ch markdown th√†nh c√°c ph·∫ßn: text, code blocks, links, etc."""
    parts = []
    i = 0
    
    # Pattern cho code blocks
    code_block_pattern = re.compile(r'```[\s\S]*?```')
    # Pattern cho inline code
    inline_code_pattern = re.compile(r'`[^`]+`')
    # Pattern cho links
    link_pattern = re.compile(r'\[([^\]]+)\]\(([^\)]+)\)')
    # Pattern cho URLs
    url_pattern = re.compile(r'https?://[^\s\)]+')
    
    while i < len(content):
        # T√¨m code block
        code_match = code_block_pattern.search(content, i)
        if code_match:
            # Text tr∆∞·ªõc code block
            if code_match.start() > i:
                text_before = content[i:code_match.start()]
                parts.append(('text', text_before))
            # Code block
            parts.append(('code', code_match.group()))
            i = code_match.end()
            continue
        
        # N·∫øu kh√¥ng c√≥ code block, x·ª≠ l√Ω text b√¨nh th∆∞·ªùng
        # T√¨m code block ti·∫øp theo
        next_code = code_block_pattern.search(content, i)
        next_pos = next_code.start() if next_code else len(content)
        
        text_segment = content[i:next_pos]
        parts.append(('text', text_segment))
        i = next_pos
    
    return parts

def translate_markdown(content, source_lang='auto', target_lang='en'):
    """D·ªãch markdown content, gi·ªØ nguy√™n format"""
    if source_lang == 'auto':
        source_lang = detect_language(content[:500])  # L·∫•y m·∫´u ƒë·ªÉ detect
    
    # Normalize language codes
    source_lang = LANG_MAP.get(source_lang.lower(), source_lang)
    target_lang = LANG_MAP.get(target_lang.lower(), target_lang)
    
    print(f"üåê D·ªãch t·ª´ {source_lang} sang {target_lang}...")
    
    # Ph√¢n t√≠ch markdown
    parts = parse_markdown(content)
    
    # Kh·ªüi t·∫°o translator
    translator = None
    if HAS_DEEP_TRANSLATOR:
        translator = GoogleTranslator(source=source_lang, target=target_lang)
    elif HAS_GOOGLETRANS:
        translator = Translator()
    
    translated_parts = []
    total_parts = len([p for p in parts if p[0] == 'text'])
    current_part = 0
    
    for part_type, part_content in parts:
        if part_type == 'code':
            # Gi·ªØ nguy√™n code blocks
            translated_parts.append(part_content)
        else:
            # D·ªãch text, nh∆∞ng gi·ªØ nguy√™n inline code v√† links
            text = part_content
            
            # B·∫£o v·ªá inline code
            inline_codes = {}
            code_counter = 0
            for match in re.finditer(r'`([^`]+)`', text):
                placeholder = f"__INLINE_CODE_{code_counter}__"
                inline_codes[placeholder] = match.group(0)
                text = text.replace(match.group(0), placeholder)
                code_counter += 1
            
            # B·∫£o v·ªá URLs
            urls = {}
            url_counter = 0
            for match in re.finditer(r'https?://[^\s\)]+', text):
                placeholder = f"__URL_{url_counter}__"
                urls[placeholder] = match.group(0)
                text = text.replace(match.group(0), placeholder)
                url_counter += 1
            
            # B·∫£o v·ªá links [text](url)
            links = {}
            link_counter = 0
            for match in re.finditer(r'\[([^\]]+)\]\(([^\)]+)\)', text):
                placeholder = f"__LINK_{link_counter}__"
                links[placeholder] = match.group(0)
                text = text.replace(match.group(0), placeholder)
                link_counter += 1
            
            # D·ªãch text
            if text.strip():
                current_part += 1
                print(f"üìù ƒêang d·ªãch ph·∫ßn {current_part}/{total_parts}...", end='\r')
                translated = translate_text(text, source_lang, target_lang, translator)
            else:
                translated = text
            
            # Kh√¥i ph·ª•c inline code
            for placeholder, original in inline_codes.items():
                translated = translated.replace(placeholder, original)
            
            # Kh√¥i ph·ª•c URLs
            for placeholder, original in urls.items():
                translated = translated.replace(placeholder, original)
            
            # Kh√¥i ph·ª•c links
            for placeholder, original in links.items():
                translated = translated.replace(placeholder, original)
            
            translated_parts.append(translated)
    
    print(f"\n‚úÖ ƒê√£ d·ªãch {current_part} ph·∫ßn text")
    return ''.join(translated_parts)

def main():
    parser = argparse.ArgumentParser(description="D·ªãch file README.md")
    parser.add_argument("--source", default="README.md", help="File README ngu·ªìn (m·∫∑c ƒë·ªãnh: README.md)")
    parser.add_argument("--target", default="en", help="Ng√¥n ng·ªØ ƒë√≠ch: en, vi (m·∫∑c ƒë·ªãnh: en)")
    parser.add_argument("--output", help="File output (m·∫∑c ƒë·ªãnh: README_{target}.md)")
    parser.add_argument("--from-lang", default="auto", help="Ng√¥n ng·ªØ ngu·ªìn: auto, vi, en (m·∫∑c ƒë·ªãnh: auto)")
    
    args = parser.parse_args()
    
    # Ki·ªÉm tra th∆∞ vi·ªán d·ªãch
    if not HAS_DEEP_TRANSLATOR and not HAS_GOOGLETRANS:
        print("‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ vi·ªán d·ªãch!")
        print("üì¶ C√†i ƒë·∫∑t m·ªôt trong c√°c th∆∞ vi·ªán sau:")
        print("   pip install deep-translator")
        print("   ho·∫∑c")
        print("   pip install googletrans==4.0.0rc1")
        sys.exit(1)
    
    # ƒê·ªçc file
    source_path = Path(args.source)
    if not source_path.exists():
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {args.source}")
        sys.exit(1)
    
    print(f"üìñ ƒê·ªçc file: {args.source}")
    with open(source_path, "r", encoding="utf-8") as f:
        content = f.read()
    
    # X√°c ƒë·ªãnh file output
    if args.output:
        output_path = Path(args.output)
    else:
        target_suffix = args.target.upper() if args.target == 'en' else args.target
        output_path = source_path.parent / f"README_{target_suffix}.md"
    
    # D·ªãch
    print(f"üîÑ B·∫Øt ƒë·∫ßu d·ªãch...")
    translated_content = translate_markdown(content, args.from_lang, args.target)
    
    # L∆∞u file
    print(f"üíæ L∆∞u file: {output_path}")
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(translated_content)
    
    print(f"‚úÖ Ho√†n th√†nh! File ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_path}")

if __name__ == "__main__":
    main()

