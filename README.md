# Recipe Chatbot Agent

Há»‡ thá»‘ng chatbot tÃ¬m kiáº¿m cÃ´ng thá»©c náº¥u Äƒn sá»­ dá»¥ng vector search vá»›i FAISS vÃ  sentence transformers.

## ğŸ“‹ MÃ´ táº£

Dá»± Ã¡n nÃ y bao gá»“m:
- **prepare_recipes.py**: Chuáº©n hÃ³a dá»¯ liá»‡u recipes tá»« JSON hoáº·c API thÃ nh Ä‘á»‹nh dáº¡ng JSONL
- **embed_and_index.py**: Táº¡o embeddings vÃ  xÃ¢y dá»±ng FAISS index cho vector search
- **serve_vector.py**: FastAPI server cung cáº¥p API Ä‘á»ƒ tÃ¬m kiáº¿m vÃ  train

## ğŸš€ CÃ i Ä‘áº·t

### 1. Táº¡o virtual environment

```powershell
# Windows PowerShell
python -m venv .venv
.venv\Scripts\Activate.ps1

# Hoáº·c náº¿u gáº·p lá»—i execution policy:
Set-ExecutionPolicy -ExecutionPolicy Bypass -Scope Process
. .venv\Scripts\Activate.ps1
```

```bash
# Linux/Mac
python -m venv .venv
source .venv/bin/activate
```

### 2. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

**LÆ°u Ã½**: TrÃªn Windows, `faiss-cpu` sáº½ Ä‘Æ°á»£c cÃ i tá»± Ä‘á»™ng. Náº¿u gáº·p lá»—i, cÃ i thá»§ cÃ´ng:
```bash
pip install faiss-cpu
```

## ğŸ“– CÃ¡ch sá»­ dá»¥ng

### CÃ¡ch 1: Cháº¡y tá»± Ä‘á»™ng vá»›i script (Khuyáº¿n nghá»‹)

#### Windows PowerShell:
```powershell
# Cháº¡y Ä‘áº§y Ä‘á»§ pipeline (prepare -> embed -> serve)
.\run.ps1

# Hoáº·c vá»›i cÃ¡c tÃ¹y chá»n:
.\run.ps1 -Source recipes.json -Port 8000 -Reload

# Bá» qua cÃ¡c bÆ°á»›c Ä‘Ã£ cháº¡y:
.\run.ps1 -SkipPrepare -SkipEmbed  # Chá»‰ cháº¡y server
.\run.ps1 -SkipEmbed  # Cháº¡y prepare vÃ  server
```

#### Python (Cross-platform):
```bash
# Cháº¡y Ä‘áº§y Ä‘á»§ pipeline
python run.py

# Hoáº·c vá»›i cÃ¡c tÃ¹y chá»n:
python run.py --source recipes.json --port 8000 --reload

# Bá» qua cÃ¡c bÆ°á»›c Ä‘Ã£ cháº¡y:
python run.py --skip-prepare --skip-embed  # Chá»‰ cháº¡y server
python run.py --skip-embed  # Cháº¡y prepare vÃ  server
```

### CÃ¡ch 2: Cháº¡y tá»«ng bÆ°á»›c thá»§ cÃ´ng

#### BÆ°á»›c 1: Chuáº©n hÃ³a dá»¯ liá»‡u

```bash
# Tá»« file JSON
python prepare_recipes.py --source recipes.json --out docs.jsonl

# Tá»« API
python prepare_recipes.py --source api://http://localhost:8080/recipes/full-details --out docs.jsonl
```

#### BÆ°á»›c 2: Táº¡o embeddings vÃ  index

```bash
python embed_and_index.py --docs docs.jsonl --index out.index --meta meta.json

# Hoáº·c vá»›i model khÃ¡c
python embed_and_index.py --docs docs.jsonl --index out.index --meta meta.json --model sentence-transformers/all-mpnet-base-v2
```

#### BÆ°á»›c 3: Cháº¡y API server

```bash
# Cháº¡y server
uvicorn serve_vector:app --host 0.0.0.0 --port 8000

# Vá»›i auto-reload (development)
uvicorn serve_vector:app --reload --host 0.0.0.0 --port 8000
```

## ğŸ³ Docker Deployment

### Cháº¡y vá»›i Docker

#### Build vÃ  cháº¡y image:

```bash
# Build image
docker build -t recipe-chatbot-api .

# Cháº¡y container
docker run -d \
  -p 8000:8000 \
  -v $(pwd)/data:/app/data \
  -e VECTOR_INDEX_PATH=/app/data/out.index \
  -e VECTOR_META_PATH=/app/data/meta.json \
  --name recipe-api \
  recipe-chatbot-api
```

#### Hoáº·c sá»­ dá»¥ng Docker Compose:

```bash
# Táº¡o thÆ° má»¥c data náº¿u chÆ°a cÃ³
mkdir -p data

# Cháº¡y vá»›i docker-compose
docker-compose up -d

# Xem logs
docker-compose logs -f

# Dá»«ng
docker-compose down
```

**LÆ°u Ã½:**
- ThÆ° má»¥c `data/` sáº½ Ä‘Æ°á»£c mount Ä‘á»ƒ lÆ°u trá»¯ index files
- Náº¿u chÆ°a cÃ³ index, báº¡n cÃ³ thá»ƒ táº¡o qua endpoint `/train` sau khi container cháº¡y
- Hoáº·c copy `out.index` vÃ  `meta.json` vÃ o thÆ° má»¥c `data/` trÆ°á»›c khi cháº¡y

### Build vÃ  test Docker image:

```bash
# Build
docker build -t recipe-chatbot-api .

# Test locally
docker run -p 8000:8000 recipe-chatbot-api

# Kiá»ƒm tra health
curl http://localhost:8000/docs
```

## â˜ï¸ Deploy lÃªn Render

### CÃ¡ch 1: Sá»­ dá»¥ng render.yaml (Khuyáº¿n nghá»‹)

1. **Push code lÃªn GitHub/GitLab**
   ```bash
   git add .
   git commit -m "Add Docker and Render config"
   git push origin main
   ```

2. **Táº¡o service trÃªn Render:**
   - ÄÄƒng nháº­p [Render Dashboard](https://dashboard.render.com)
   - Chá»n "New" â†’ "Blueprint"
   - Connect repository
   - Render sáº½ tá»± Ä‘á»™ng detect `render.yaml` vÃ  deploy

3. **Cáº¥u hÃ¬nh Environment Variables** (náº¿u cáº§n):
   - `VECTOR_INDEX_PATH`: `/opt/render/project/src/data/out.index`
   - `VECTOR_META_PATH`: `/opt/render/project/src/data/meta.json`
   - `EMBED_MODEL`: `sentence-transformers/all-MiniLM-L6-v2`

4. **Táº¡o index sau khi deploy:**
   - Sau khi service cháº¡y, gá»i endpoint `/train` Ä‘á»ƒ táº¡o index:
   ```bash
   curl -X POST "https://your-app.onrender.com/train" \
     -H "Content-Type: application/json" \
     -d '{
       "source_url": "http://your-api.com/recipes/full-details",
       "chunk_size": 1024
     }'
   ```

### CÃ¡ch 2: Deploy thá»§ cÃ´ng trÃªn Render

1. **Táº¡o Web Service:**
   - Chá»n "New" â†’ "Web Service"
   - Connect repository
   - Cáº¥u hÃ¬nh:
     - **Build Command**: `pip install -r requirements.txt`
     - **Start Command**: `uvicorn serve_vector:app --host 0.0.0.0 --port $PORT`
     - **Environment**: `Python 3`

2. **ThÃªm Persistent Disk** (Ä‘á»ƒ lÆ°u index):
   - Settings â†’ Disks â†’ Add Disk
   - Mount path: `/opt/render/project/src/data`
   - Size: 1GB (hoáº·c lá»›n hÆ¡n tÃ¹y nhu cáº§u)

3. **Environment Variables:**
   ```
   VECTOR_INDEX_PATH=/opt/render/project/src/data/out.index
   VECTOR_META_PATH=/opt/render/project/src/data/meta.json
   EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
   ```

4. **Deploy vÃ  táº¡o index:**
   - Sau khi deploy thÃ nh cÃ´ng, sá»­ dá»¥ng endpoint `/train` Ä‘á»ƒ táº¡o index

### LÆ°u Ã½ khi deploy lÃªn Render:

- **Build time**: Láº§n Ä‘áº§u build cÃ³ thá»ƒ máº¥t 5-10 phÃºt do cÃ i Ä‘áº·t dependencies
- **Cold start**: Service cÃ³ thá»ƒ máº¥t 30-60 giÃ¢y Ä‘á»ƒ start láº§n Ä‘áº§u
- **Memory**: Äáº£m báº£o plan Ä‘á»§ RAM (tá»‘i thiá»ƒu 512MB, khuyáº¿n nghá»‹ 1GB+)
- **Disk**: Sá»­ dá»¥ng Persistent Disk Ä‘á»ƒ lÆ°u index files
- **Auto-deploy**: Render tá»± Ä‘á»™ng deploy khi cÃ³ commit má»›i (náº¿u báº­t)

## ğŸ”„ GitHub Actions CI/CD

Dá»± Ã¡n Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh vá»›i GitHub Actions Ä‘á»ƒ tá»± Ä‘á»™ng build vÃ  push Docker image lÃªn Docker Hub.

### Workflow:

**Docker Deploy** (`.github/workflows/docker-deploy.yml`)
- Tá»± Ä‘á»™ng build Docker image khi push code vÃ o `main`/`master` branch
- Build image sá»­ dá»¥ng `docker-compose.prod.yml` vá»›i profile `prod`
- Tag image vá»›i: `latest`, commit SHA, vÃ  branch name
- Push image lÃªn Docker Hub

### Cáº¥u hÃ¬nh GitHub Secrets:

Äá»ƒ workflow hoáº¡t Ä‘á»™ng, cáº§n thÃªm cÃ¡c secrets sau trong GitHub repository:

**Settings â†’ Secrets and variables â†’ Actions â†’ New repository secret**

1. **Docker Hub Credentials** (báº¯t buá»™c):
   ```
   DOCKER_USERNAME=your_dockerhub_username
   DOCKER_PASSWORD=your_dockerhub_password
   ```

### CÃ¡ch láº¥y Docker Hub credentials:

1. ÄÄƒng nháº­p [Docker Hub](https://hub.docker.com)
2. VÃ o **Account Settings** â†’ **Security**
3. Táº¡o Access Token má»›i (khuyáº¿n nghá»‹) hoáº·c dÃ¹ng password
4. ThÃªm vÃ o GitHub Secrets:
   - `DOCKER_USERNAME`: TÃªn Ä‘Äƒng nháº­p Docker Hub
   - `DOCKER_PASSWORD`: Access Token hoáº·c password

### Trigger workflow:

- **Tá»± Ä‘á»™ng**: Khi push code vÃ o `main`/`master` branch
- **Manual**: VÃ o **Actions** tab â†’ Chá»n "Docker Image CI" â†’ **Run workflow**

### Xem káº¿t quáº£:

- VÃ o tab **Actions** trÃªn GitHub repository
- Xem logs vÃ  káº¿t quáº£ cá»§a workflow run
- Docker images sáº½ Ä‘Æ°á»£c push lÃªn: `your-username/recipe-chatbot-api`

### Pull vÃ  cháº¡y image tá»« Docker Hub:

```bash
# Pull latest image
docker pull your-username/recipe-chatbot-api:latest

# Cháº¡y container
docker run -d \
  -p 8000:8000 \
  -v $(pwd)/data:/app/data \
  --name recipe-api \
  your-username/recipe-chatbot-api:latest
```

## ğŸ”Œ API Endpoints

Sau khi server cháº¡y, truy cáº­p:
- **API Documentation**: http://localhost:8000/docs
- **Alternative docs**: http://localhost:8000/redoc

### 1. POST `/search` - TÃ¬m kiáº¿m recipes

TÃ¬m kiáº¿m recipes dá»±a trÃªn query text.

**Request:**
```json
{
  "q": "cÃ¡ch náº¥u phá»Ÿ bÃ²",
  "k": 5
}
```

**Response:**
```json
{
  "results": [
    {
      "score": 0.85,
      "meta": {
        "id": "recipe-123",
        "title": "Phá»Ÿ BÃ²",
        "text": "Title: Phá»Ÿ BÃ²\nIngredients: ...\nSteps: ..."
      }
    }
  ]
}
```

**VÃ­ dá»¥ vá»›i curl:**
```bash
curl -X POST "http://localhost:8000/search" \
  -H "Content-Type: application/json" \
  -d '{"q": "cÃ¡ch náº¥u phá»Ÿ bÃ²", "k": 5}'
```

### 2. POST `/train` - Train/index dá»¯ liá»‡u má»›i

Train láº¡i index tá»« API URL hoáº·c cáº­p nháº­t index.

**Request:**
```json
{
  "source_url": "http://localhost:8080/recipes/full-details",
  "index_path": "out.index",
  "meta_path": "meta.json",
  "model": "sentence-transformers/all-MiniLM-L6-v2",
  "chunk_size": 1024,
  "chunk_overlap": 80
}
```

**Response:**
```json
{
  "status": "ok",
  "indexed": 150,
  "index_path": "out.index",
  "meta_path": "meta.json"
}
```

**VÃ­ dá»¥ vá»›i curl:**
```bash
curl -X POST "http://localhost:8000/train" \
  -H "Content-Type: application/json" \
  -d '{
    "source_url": "http://localhost:8080/recipes/full-details",
    "chunk_size": 1024
  }'
```

## âš™ï¸ Cáº¥u hÃ¬nh

### Environment Variables

CÃ³ thá»ƒ cáº¥u hÃ¬nh qua biáº¿n mÃ´i trÆ°á»ng:

```bash
# Windows PowerShell
$env:VECTOR_INDEX_PATH="out.index"
$env:VECTOR_META_PATH="meta.json"
$env:EMBED_MODEL="sentence-transformers/all-MiniLM-L6-v2"
$env:OLLAMA_URL="http://localhost:11434"
$env:OLLAMA_MODEL="llama3.2:latest"

# Linux/Mac
export VECTOR_INDEX_PATH="out.index"
export VECTOR_META_PATH="meta.json"
export EMBED_MODEL="sentence-transformers/all-MiniLM-L6-v2"
```

### File cáº¥u hÃ¬nh

- `INDEX_PATH`: ÄÆ°á»ng dáº«n Ä‘áº¿n file FAISS index (máº·c Ä‘á»‹nh: `out.index`)
- `META_PATH`: ÄÆ°á»ng dáº«n Ä‘áº¿n file metadata (máº·c Ä‘á»‹nh: `meta.json`)
- `EMBED_MODEL`: Model embedding (máº·c Ä‘á»‹nh: `sentence-transformers/all-MiniLM-L6-v2`)
- `OLLAMA_URL`: URL cá»§a Ollama server (máº·c Ä‘á»‹nh: `http://host.docker.internal:11434`)
- `OLLAMA_MODEL`: Model Ollama (máº·c Ä‘á»‹nh: `llama3.2:latest`)

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
recipe_chatbot_agent/
â”œâ”€â”€ prepare_recipes.py      # Chuáº©n hÃ³a dá»¯ liá»‡u recipes
â”œâ”€â”€ embed_and_index.py      # Táº¡o embeddings vÃ  index
â”œâ”€â”€ serve_vector.py         # FastAPI server
â”œâ”€â”€ run.py                  # Script Python tá»± Ä‘á»™ng
â”œâ”€â”€ run.ps1                 # Script PowerShell tá»± Ä‘á»™ng
â”œâ”€â”€ translate_readme.py     # Script dá»‹ch README.md
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ Dockerfile              # Docker image configuration
â”œâ”€â”€ docker-compose.yml      # Docker Compose configuration
â”œâ”€â”€ docker-entrypoint.sh    # Docker startup script
â”œâ”€â”€ render.yaml             # Render.com deployment config
â”œâ”€â”€ .dockerignore           # Docker ignore patterns
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/          # GitHub Actions workflows
â”‚       â””â”€â”€ docker-deploy.yml # Docker build & push to Docker Hub
â”œâ”€â”€ docker-compose.prod.yml  # Docker Compose config for production build
â”œâ”€â”€ recipes.json            # Dá»¯ liá»‡u recipes (input)
â”œâ”€â”€ docs.jsonl              # Dá»¯ liá»‡u Ä‘Ã£ chuáº©n hÃ³a (output)
â”œâ”€â”€ data/                   # ThÆ° má»¥c lÆ°u index (Docker/Render)
â”‚   â”œâ”€â”€ out.index           # FAISS index (output)
â”‚   â””â”€â”€ meta.json           # Metadata (output)
â””â”€â”€ README.md               # File nÃ y
```

## ğŸ”§ Troubleshooting

### Lá»—i: ModuleNotFoundError: No module named 'faiss'

**Giáº£i phÃ¡p:**
```bash
# Äáº£m báº£o Ä‘ang dÃ¹ng Python tá»« venv
.venv\Scripts\python.exe -m pip install faiss-cpu

# Hoáº·c náº¿u trÃªn Linux/Mac
.venv/bin/pip install faiss-cpu
```

### Lá»—i: Execution Policy trong PowerShell

**Giáº£i phÃ¡p:**
```powershell
# Bypass cho session hiá»‡n táº¡i
Set-ExecutionPolicy -ExecutionPolicy Bypass -Scope Process

# Hoáº·c dÃ¹ng activate.bat thay vÃ¬ Activate.ps1
.venv\Scripts\activate.bat
```

### Lá»—i: FileNotFoundError khi search

**Giáº£i phÃ¡p:**
- Äáº£m báº£o Ä‘Ã£ cháº¡y `embed_and_index.py` Ä‘á»ƒ táº¡o `out.index` vÃ  `meta.json`
- Hoáº·c dÃ¹ng endpoint `/train` Ä‘á»ƒ táº¡o index tá»« API

### Lá»—i: torch/torchvision compatibility

**Giáº£i phÃ¡p:**
```bash
pip install --upgrade --force-reinstall torchvision==0.24.1
```

## ğŸŒ Dá»‹ch README

Script `translate_readme.py` giÃºp dá»‹ch README.md sang ngÃ´n ngá»¯ khÃ¡c, tá»± Ä‘á»™ng giá»¯ nguyÃªn format markdown, code blocks, vÃ  links.

### CÃ i Ä‘áº·t thÆ° viá»‡n dá»‹ch

```bash
pip install deep-translator
```

### Sá»­ dá»¥ng

```bash
# Dá»‹ch README.md sang tiáº¿ng Anh (máº·c Ä‘á»‹nh)
python translate_readme.py

# Dá»‹ch sang tiáº¿ng Viá»‡t
python translate_readme.py --target vi --output README_VI.md

# Dá»‹ch tá»« file khÃ¡c
python translate_readme.py --source README_VI.md --target en --output README_EN.md

# Chá»‰ Ä‘á»‹nh ngÃ´n ngá»¯ nguá»“n (náº¿u auto-detect khÃ´ng chÃ­nh xÃ¡c)
python translate_readme.py --from-lang vi --target en
```

**TÃ¹y chá»n:**
- `--source`: File README nguá»“n (máº·c Ä‘á»‹nh: `README.md`)
- `--target`: NgÃ´n ngá»¯ Ä‘Ã­ch: `en`, `vi` (máº·c Ä‘á»‹nh: `en`)
- `--output`: File output (máº·c Ä‘á»‹nh: `README_{target}.md`)
- `--from-lang`: NgÃ´n ngá»¯ nguá»“n: `auto`, `vi`, `en` (máº·c Ä‘á»‹nh: `auto`)

**LÆ°u Ã½:**
- Script tá»± Ä‘á»™ng phÃ¡t hiá»‡n vÃ  giá»¯ nguyÃªn code blocks, inline code, links, vÃ  URLs
- Chá»‰ dá»‹ch pháº§n text, khÃ´ng dá»‹ch code hoáº·c URLs
- Sá»­ dá»¥ng Google Translate API (miá»…n phÃ­)

## ğŸ“ Ghi chÃº

- Model embedding máº·c Ä‘á»‹nh: `sentence-transformers/all-MiniLM-L6-v2` (384 dimensions)
- Chunk size máº·c Ä‘á»‹nh: 1024 kÃ½ tá»± vá»›i overlap 80 kÃ½ tá»±
- Index sá»­ dá»¥ng FAISS IndexFlatIP (Inner Product cho cosine similarity)
- Embeddings Ä‘Æ°á»£c normalize Ä‘á»ƒ sá»­ dá»¥ng cosine similarity

## ğŸ¤ ÄÃ³ng gÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n! Vui lÃ²ng táº¡o issue hoáº·c pull request.

## ğŸ“„ License

MIT License

